<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Jefferson Ong" />

<meta name="date" content="2020-06-02" />

<title>Divorce Predictors Data Set</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Jefferson Ong</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="JeffersonOngResume.html">Resume</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="supervise.html">Divorce Predictor Data</a>
    </li>
    <li>
      <a href="WriteUp.html">Breast Cancer Data</a>
    </li>
    <li>
      <a href="house.html">Housing Data in Oregon</a>
    </li>
    <li>
      <a href="Project2.html">Statistical Methods on Housing Data</a>
    </li>
    <li>
      <a href="Research.html">Microtonal Research</a>
    </li>
    <li>
      <a href="nume.html">Root Finding &amp; Interpolation</a>
    </li>
  </ul>
</li>
<li>
  <a href="about.html">Research Interest</a>
</li>
<li>
  <a href="Contacts.html">Contacts</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ongjk">
    <span class="fa fa-github fa-lg"></span>
     
    
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Divorce Predictors Data Set</h1>
<h4 class="author">Jefferson Ong</h4>
<h4 class="date">June 02, 2020</h4>

</div>


<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>A study done in Turkey attempts to answer what are the important questions that will lead to a divorce. The dataset can be found in the <a href="https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set#">UCI Machine Learning Repository</a>. <span class="citation">(“UCI Machine Learning Repository: Divorce Predictors Data Set Data Set” 2020)</span> The paper itself can be found <a href="http://dergipark.org.tr/en/pub/nevsosbilen/issue/46568/549416">here</a>. They used a questionnaire base on Gottman's approach to couples therapy. It consist of 54 different statements related to marriage such as &quot;I enjoy our holidays with my wife.&quot; or &quot;I'm not the one who's wrong about problems at home.&quot;. Participants are asked to rate their response as an integer from 0 to 5, presumably 0 for strongly agree and 5 for strongly disagree. They are also classified as either married or divorced, where 0 corresponds to married and 1 corresponds to divorce. <span class="citation">Yöntem et al. (2019)</span></p>
<p>We will attempt attempt to verify the model accuracy as well as which predictors are significant to discerning whether someone is divorced or not. We will primarily look into the random forest model and use mean decrease inpurity as our metric of importance. Going further we will look at which predictors aren't important in discerning divorce vs. married.</p>
</div>
<div id="methods" class="section level1">
<h1><span class="header-section-number">2</span> Methods</h1>
<div id="data-collection" class="section level2">
<h2><span class="header-section-number">2.1</span> Data Collection</h2>
<p>The data was taken at the UCI machine learning repository here: <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/00497/" class="uri">https://archive.ics.uci.edu/ml/machine-learning-databases/00497/</a></p>
<p>During this time, June 02, 2020, using the <code>R</code> programming language. The machine learning repository needed further citation on the paper. From what it seems, it is indeed the correct paper and dataset as I was able to reproduce most of the code. The researchers conducted face to face interviews and google drive forms to administer the questionnaire. It has no missing values.</p>
</div>
<div id="exploratory-analysis" class="section level2">
<h2><span class="header-section-number">2.2</span> Exploratory Analysis</h2>
<p>Exploratory Analysis was performed using contingency tables, faceted line graphs, and scatterplots of correlations of the data in tidy format. The data is evenly split between married and divorce, with 84 participants divorced and 86 married. Further statistic is provided in the paper, with 74 participants married for love and 96 were arrange marriage. Only the first claim could be verified.</p>
<p>Going further with the data, the mean response value for those that are married is 0.55 while those that are divorced is 3.05. Participant response is heavily weighted to 0, strongly agree.</p>
</div>
<div id="statistical-modeling" class="section level2">
<h2><span class="header-section-number">2.3</span> Statistical Modeling</h2>
<p>A simple logistic regression with predictor <code>Class</code> and the rest as the response was done. Showing none as a significant predictor. This is using the <code>glm</code> model with a family of binomial distribution. We, then started to use training, test/validation sets. Using the <code>caret</code> package to build a random forest model with bootstrap resampling. <span class="citation">Arnholt (2020)</span></p>
</div>
<div id="reproducibility" class="section level2">
<h2><span class="header-section-number">2.4</span> Reproducibility</h2>
<p>All analysis used in this paper can be reproduced by using the original dataset with RStudio. The <code>R</code> packages use were <code>randomForest</code><span class="citation">(Cutler and Wiener 2018)</span>, <code>caret</code> <span class="citation">(Kuhn 2020)</span>, <code>Yardstick</code> <span class="citation">(Kuhn, Vaughan, and RStudio 2020)</span>, <code>readxl</code> <span class="citation">(“Readxl Package | R Documentation” 2020)</span>, <code>tidyverse</code> <span class="citation">(Wickham and RStudio 2019)</span>. These libraries must be loaded for the code to work.</p>
</div>
</div>
<div id="results" class="section level1">
<h1><span class="header-section-number">3</span> Results</h1>
<p>The data partitioning percentage for the training is 60% and 40% validation/test set. The validation and testing set was partitioned evenly. This is our <code>glm</code> model using bootstrap resampling.</p>
<pre><code>Generalized Linear Model 

103 samples
 54 predictor
  2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 103, 103, 103, 103, 103, 103, ... 
Resampling results:

  Accuracy   Kappa    
  0.7501027  0.4985343</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 15  2
         1  2 15
                                         
               Accuracy : 0.8824         
                 95% CI : (0.7255, 0.967)
    No Information Rate : 0.5            
    P-Value [Acc &gt; NIR] : 3.082e-06      
                                         
                  Kappa : 0.7647         
                                         
 Mcnemar&#39;s Test P-Value : 1              
                                         
            Sensitivity : 0.8824         
            Specificity : 0.8824         
         Pos Pred Value : 0.8824         
         Neg Pred Value : 0.8824         
             Prevalence : 0.5000         
         Detection Rate : 0.4412         
   Detection Prevalence : 0.5000         
      Balanced Accuracy : 0.8824         
                                         
       &#39;Positive&#39; Class : 0              
                                         </code></pre>
<pre><code>Random Forest 

103 samples
 54 predictor
  2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 103, 103, 103, 103, 103, 103, ... 
Addtional sampling using up-sampling

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
   2    0.9667393  0.9324827
  28    0.9636570  0.9261996
  54    0.9563806  0.9115297

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 2.</code></pre>
<p>We moved on to reproduce the paper's result on random forest accuracy. The paper had 6 predictor variables was the optimal model, we tuned our random forest model with mtry of 6 due to this, which has an accuracy of 0.97, similar value on Table 2. in the paper. This is however not the case for the mtry 54 for the random forest model, where we were able to only achieve an accuracy of 0.96 while the paper's model achieved 97.64, unsure on the discrepancies.</p>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 17  0
         1  0 17
                                     
               Accuracy : 1          
                 95% CI : (0.8972, 1)
    No Information Rate : 0.5        
    P-Value [Acc &gt; NIR] : 5.821e-11  
                                     
                  Kappa : 1          
                                     
 Mcnemar&#39;s Test P-Value : NA         
                                     
            Sensitivity : 1.0        
            Specificity : 1.0        
         Pos Pred Value : 1.0        
         Neg Pred Value : 1.0        
             Prevalence : 0.5        
         Detection Rate : 0.5        
   Detection Prevalence : 0.5        
      Balanced Accuracy : 1.0        
                                     
       &#39;Positive&#39; Class : 0          
                                     </code></pre>
<p>My random forest model was able to have 100% accuracy rating against the testing set while the simple logistic model had an accuracy of 88.235%. However there is clear overfitting here.</p>
<pre><code>Random Forest 

170 samples
 54 predictor
  2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 136, 136, 137, 135, 136 
Resampling results:

  Accuracy   Kappa    
  0.9762923  0.9525512

Tuning parameter &#39;mtry&#39; was held constant at a value of 6
Tuning
 parameter &#39;splitrule&#39; was held constant at a value of gini
Tuning
 parameter &#39;min.node.size&#39; was held constant at a value of 5</code></pre>
<pre><code>Ranger result

Call:
 ranger::ranger(dependent.variable.name = &quot;.outcome&quot;, data = x,      mtry = min(param$mtry, ncol(x)), min.node.size = param$min.node.size,      splitrule = as.character(param$splitrule), write.forest = TRUE,      probability = classProbs, ...) 

Type:                             Classification 
Number of trees:                  500 
Sample size:                      170 
Number of independent variables:  54 
Mtry:                             6 
Target node size:                 5 
Variable importance mode:         none 
Splitrule:                        gini 
OOB prediction error:             2.35 % </code></pre>
<p>We compare the simple <code>glm</code> model to the random forest model here on their accuracy onto the test set</p>
<p>We, then started to look at the mean decrease accuracy for the random forest model using the tuning parameter of gini. Using 2000 trees, we've narrowed down the most significant predictors as question 9, 11, 18, 19, 26, and 40. The paper however recorded 2, 6, 11, 18, 26, 40.</p>
<pre><code>            0        1 MeanDecreaseAccuracy MeanDecreaseGini
Atr1 6.013093 4.505396             6.195657       0.41616523
Atr2 8.552669 1.917795             8.220454       0.32659203
Atr3 7.151254 3.540141             7.051627       0.23923488
Atr4 6.443269 4.053108             6.495865       0.76783469
Atr5 6.872992 3.867602             7.327225       0.96456254
Atr6 3.948326 2.299726             4.327478       0.05818228</code></pre>
<p><img src="supervise_files/figure-html/unnamed-chunk-12-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre><code>     MeanDecreaseAccuracy MeanDecreaseGini
Atr1             6.195657       0.41616523
Atr2             8.220454       0.32659203
Atr3             7.051627       0.23923488
Atr4             6.495865       0.76783469
Atr5             7.327225       0.96456254
Atr6             4.327478       0.05818228</code></pre>
<p>Here are the questions for those interested.</p>
<ul>
<li><ol start="2" style="list-style-type: decimal">
<li>I know we can ignore our differences even if things get though sometimes</li>
</ol></li>
<li><ol start="6" style="list-style-type: decimal">
<li>We don't have a common time we spent together at home.</li>
</ol></li>
<li><ol start="9" style="list-style-type: decimal">
<li>I enjoy traveling with my wife.18. My spouse and I have similar ideas about how marriage should be</li>
</ol></li>
<li><ol start="11" style="list-style-type: decimal">
<li>I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.</li>
</ol></li>
<li><ol start="18" style="list-style-type: decimal">
<li>My spouse and I have similar ideas about how marriage should be</li>
</ol></li>
<li><ol start="19" style="list-style-type: decimal">
<li>My spouse and I have similar ideas about how roles should be in marriage</li>
</ol></li>
<li><ol start="26" style="list-style-type: decimal">
<li>I know my spouse's basic anxieties.</li>
</ol></li>
<li><ol start="40" style="list-style-type: decimal">
<li>We're just starting a discussion before I know what's going on.</li>
</ol></li>
</ul>
<p>These are the least significant from my model</p>
<ul>
<li><ol start="23" style="list-style-type: decimal">
<li>I know my spouse's favorite food.</li>
</ol></li>
<li><ol start="45" style="list-style-type: decimal">
<li>I'd rather stay silent than discuss with my spouse.</li>
</ol></li>
<li><ol start="46" style="list-style-type: decimal">
<li>Even if I'm right in the discussion, I stay silent to hurt my spouse.</li>
</ol></li>
<li><ol start="47" style="list-style-type: decimal">
<li>When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.</li>
</ol></li>
<li><ol start="48" style="list-style-type: decimal">
<li>I feel right in our discussions.</li>
</ol></li>
<li><ol start="51" style="list-style-type: decimal">
<li>I'm not the one who's wrong about problems at home.</li>
</ol></li>
</ul>
</div>
<div id="conclusions" class="section level1">
<h1><span class="header-section-number">4</span> Conclusions</h1>
<p>The primary goal of this analysis was to reproduce portions of the paper, while there were similarities in the final models, there were still discrepancies I wasn't able to reproduce. This is likely due to a tuning parameter or the particular seed used. Of the 6 most significant predictors, we were able to identify 4. Question 11, 18 makes sense intuitively how why those issues are important. Question 26, 40 on the other hand are more suprising as they deal with uncertainty. The least significant predictors also can intuitively understood, for example question 23, a spouse's favorite food. It would be more perplexing if the model recognized it as significant. The data collecting methods of the researchers isn't particularly representative of marriage on the otherhand. This particular dataset picked participants ensuring that the marriage participants did not have thoughts of divorce, this could leave out unhappy marriages that do not divorce. Other metrics such as percent of divorce, percent of arrange marriage, etc. would put any predictive answers into question.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-arnholtChapterStackOverflow">
<p>Arnholt, Alan T. 2020. <em>Chapter 3 Stack Overflow Developer Survey | Supervised Learning in R: Case Studies</em>. Accessed April 21. <a href="https://stat-ata-asu.github.io/SupervisedLearningCaseStudies/stack-overflow-developer-survey.html#training-models" class="uri">https://stat-ata-asu.github.io/SupervisedLearningCaseStudies/stack-overflow-developer-survey.html#training-models</a>.</p>
</div>
<div id="ref-cutlerRandomForestBreimanCutler2018">
<p>Cutler, Fortran original by Leo Breiman and Adele, and R. port by Andy Liaw and Matthew Wiener. 2018. <em>randomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em> (version 4.6-14). <a href="https://CRAN.R-project.org/package=randomForest" class="uri">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-kuhnCaretPackage">
<p>Kuhn, Max. 2020. <em>The Caret Package</em>. Accessed April 21. <a href="https://topepo.github.io/caret/index.html" class="uri">https://topepo.github.io/caret/index.html</a>.</p>
</div>
<div id="ref-kuhnYardstickTidyCharacterizations2020">
<p>Kuhn, Max, Davis Vaughan, and RStudio. 2020. <em>Yardstick: Tidy Characterizations of Model Performance</em> (version 0.0.6). <a href="https://CRAN.R-project.org/package=yardstick" class="uri">https://CRAN.R-project.org/package=yardstick</a>.</p>
</div>
<div id="ref-ReadxlPackageDocumentation">
<p>“Readxl Package | R Documentation.” 2020. Accessed April 21. <a href="https://www.rdocumentation.org/packages/readxl/versions/0.1.1" class="uri">https://www.rdocumentation.org/packages/readxl/versions/0.1.1</a>.</p>
</div>
<div id="ref-UCIMachineLearning">
<p>“UCI Machine Learning Repository: Divorce Predictors Data Set Data Set.” 2020. Accessed April 21. <a href="https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set#" class="uri">https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set#</a>.</p>
</div>
<div id="ref-wickhamTidyverseEasilyInstall2019">
<p>Wickham, Hadley, and RStudio. 2019. <em>Tidyverse: Easily Install and Load the ’Tidyverse’</em> (version 1.3.0). <a href="https://CRAN.R-project.org/package=tidyverse" class="uri">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
<div id="ref-yontemDIVORCEPREDICTIONUSING2019">
<p>Yöntem, Mustafa Kemal, Kemal Adem, Tahsin İlhan, and Serhat Kiliçarslan. 2019. “DIVORCE PREDICTION USING CORRELATION BASED FEATURE SELECTION AND ARTIFICIAL NEURAL NETWORKS.” <em>Nevşehir Hacı Bektaş Veli Üniversitesi SBE Dergisi</em> 9 (1, 1): 259–73. <a href="http://dergipark.org.tr/en/pub/nevsosbilen/549416" class="uri">http://dergipark.org.tr/en/pub/nevsosbilen/549416</a>.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
