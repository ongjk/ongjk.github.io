<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Jefferson Ong" />


<title>Breast Cancer and Machine Learning</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Jefferson Ong</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="JeffersonOngResume.html">Resume</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="supervise.html">Divorce Predictor Data</a>
    </li>
    <li>
      <a href="WriteUp.html">Breast Cancer Data</a>
    </li>
    <li>
      <a href="Research.html">Microtonal Research</a>
    </li>
    <li>
      <a href="num.html">Root Finding &amp; Interpolation</a>
    </li>
  </ul>
</li>
<li>
  <a href="about.html">Research Interest</a>
</li>
<li>
  <a href="Contacts.html">Contacts</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ongjk">
    <span class="fa fa-github fa-lg"></span>
     
    
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Breast Cancer and Machine Learning</h1>
<h4 class="author">Jefferson Ong</h4>
<h4 class="date">Last compiled: May 09, 2020</h4>

</div>


<div id="breast-cancer-data-from-coimbra-portugal" class="section level1">
<h1><span class="header-section-number">1</span> Breast Cancer data from Coimbra, Portugal</h1>
<p>I’ve looked into a breast cancer dataset taken from <a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra" class="uri">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra</a>. We will be creating predictive models that are able to distinguish between healthy individuals and those who have breast cancer based on 9 predictor variables. These predictors are taken from individual’s blood such as Glucose, Insulin, etc. as well as their age and BMI.</p>
<div id="eda" class="section level2">
<h2><span class="header-section-number">1.1</span> EDA</h2>
<pre class="r"><code>library(caret)
library(tidyverse)
library(readr)
cancer &lt;- read.csv(&quot;dataR2.csv&quot;)
which(is.na(cancer))</code></pre>
<pre><code>integer(0)</code></pre>
<pre class="r"><code>cancer$Classification &lt;- factor(ifelse(cancer$Classification == 1, &quot;Healthy&quot;, &quot;Patient&quot;))
str(cancer)</code></pre>
<pre><code>&#39;data.frame&#39;:   116 obs. of  10 variables:
 $ Age           : int  48 83 82 68 86 49 89 76 73 75 ...
 $ BMI           : num  23.5 20.7 23.1 21.4 21.1 ...
 $ Glucose       : int  70 92 91 77 92 92 77 118 97 83 ...
 $ Insulin       : num  2.71 3.12 4.5 3.23 3.55 ...
 $ HOMA          : num  0.467 0.707 1.01 0.613 0.805 ...
 $ Leptin        : num  8.81 8.84 17.94 9.88 6.7 ...
 $ Adiponectin   : num  9.7 5.43 22.43 7.17 4.82 ...
 $ Resistin      : num  8 4.06 9.28 12.77 10.58 ...
 $ MCP.1         : num  417 469 555 928 774 ...
 $ Classification: Factor w/ 2 levels &quot;Healthy&quot;,&quot;Patient&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<ul>
<li><p>The dataset has no missing values and I’ve changed <code>Classification</code> to a factor where 1 means that they are healthy and 2 means that they are a patient with breast cancer.</p></li>
<li><p>The predictor variables will all be quantitative data with 116 observations.</p></li>
</ul>
</div>
</div>
<div id="classification-model-using-glm" class="section level1">
<h1><span class="header-section-number">2</span> Classification Model using <code>glm()</code></h1>
<div id="splitting-the-data" class="section level2">
<h2><span class="header-section-number">2.1</span> Splitting the data</h2>
<pre class="r"><code>set.seed(0)
rows &lt;- sample(nrow(cancer))
cancer &lt;- cancer[rows,] #shuffles the data

split &lt;- round(nrow(cancer) * .6)
train &lt;- cancer[1:split,]
test &lt;- cancer[(split + 1):nrow(cancer),]</code></pre>
<ul>
<li>I first started off by splitting the data into a train and test set. Deciding on an arbitrary 60/40 split, where I will use 60% of the data on training and 40% to test the data on.</li>
</ul>
</div>
</div>
<div id="predicting-on-the-test-set" class="section level1">
<h1><span class="header-section-number">3</span> Predicting on the test set</h1>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction Healthy Patient
   Healthy      17       6
   Patient       3      20
                                          
               Accuracy : 0.8043          
                 95% CI : (0.6609, 0.9064)
    No Information Rate : 0.5652          
    P-Value [Acc &gt; NIR] : 0.0005869       
                                          
                  Kappa : 0.6087          
                                          
 Mcnemar&#39;s Test P-Value : 0.5049851       
                                          
            Sensitivity : 0.8500          
            Specificity : 0.7692          
         Pos Pred Value : 0.7391          
         Neg Pred Value : 0.8696          
             Prevalence : 0.4348          
         Detection Rate : 0.3696          
   Detection Prevalence : 0.5000          
      Balanced Accuracy : 0.8096          
                                          
       &#39;Positive&#39; Class : Healthy         
                                          </code></pre>
<pre><code> Accuracy 
0.8043478 </code></pre>
<ul>
<li><p>After splitting the data, I made a glm model using <code>Classification</code> as the response storign this as <code>mod</code>. We then use this model to predict into to our test dataset we held in reserve. The result of this are probabilities stored in <code>pred</code>.</p></li>
<li><p>After creating a list of “healthy”, I arbitrary set a 0.5 cutoff for the probabilities in the prediction to say that they are patients. I wanted to see how well my model performed against new data it hasn’t seen before, this is illustrated by the confusion matrix.</p></li>
<li><p>We can see that overall the model was correct about 80.43% of all cases. The model’s sensitivity of 85% is the true positive rate. It is the proportion of healthy samples that was correctly identified. The model’s specificity of 76.9% is the true negative rate. It is the proportion of patient sample that was correctly identified.</p></li>
</ul>
</div>
<div id="roc" class="section level1">
<h1><span class="header-section-number">4</span> ROC</h1>
<p>Since I had arbitrarily decided to set the cut off at 0.5 of our predicted values on whether those probabilities will correspond to either healthy or patient, maybe a different threshold will yield better results?</p>
<pre class="r"><code>library(caTools)
pred &lt;- predict(mod, newdata = test, type = &quot;response&quot;)
colAUC(pred, test$Classification, plotROC = T)</code></pre>
<p><img src="Figs/unnamed-chunk-5-1.png" width="1152" style="display: block; margin: auto;" /></p>
<pre><code>                         [,1]
Healthy vs. Patient 0.8288462</code></pre>
<ul>
<li>This ROC graph shows all the instances of different thresholds set and plots the sensitivity against (1- specificity). We see that the glm model as a whole gave a AUC of 0.8288462, meaning that as a model predicts correctly 82% of the time. Instead of using a specific threshold, we will use AUC which looks at how well the model performs as a whole at every instance.</li>
</ul>
</div>
<div id="tuning-the-glm-model-using-auc" class="section level1">
<h1><span class="header-section-number">5</span> Tuning the glm model using AUC</h1>
<pre class="r"><code># Create trainControl object: myControl
set.seed(7)
myControl &lt;- trainControl(
  method = &quot;cv&quot;,
  number = 5,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = FALSE
)

model &lt;- train(Classification ~ ., data = cancer,
               method = &quot;glm&quot;,
               trControl = myControl)

model</code></pre>
<pre><code>Generalized Linear Model 

116 samples
  9 predictor
  2 classes: &#39;Healthy&#39;, &#39;Patient&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 92, 94, 92, 93, 93 
Resampling results:

  ROC        Sens       Spec     
  0.7833566  0.6927273  0.7179487</code></pre>
<ul>
<li>Here we used the <code>trainControl()</code> to use cross validation on our dataset. Earlier we arbitrarily decided to split the dataset 60/40. Now we will run the same test but with 90/10 since we are using 10 folds, arbitrarily. Each fold however is tested on each other to reduce out of sample variance.</li>
</ul>
</div>
<div id="random-forest-vs.glmnet-model" class="section level1">
<h1><span class="header-section-number">6</span> Random Forest vs. Glmnet model</h1>
<p>We want to now use a non-linear model such as random forest or glmnet in the hopes of having a better AUC. A good thing to note is that we do not have any missing values in the dataset so we can skip preprocessing. Typically cross validation folds of 5 to 10 of the dataset would yield optimal results. We will be using 5x5 repeated cross validation for the both of our models.</p>
<div id="random-forest-model" class="section level2">
<h2><span class="header-section-number">6.1</span> Random Forest Model</h2>
<p>We will be using the <code>tuneLength = 9</code> since our data has 9 predictor variables so it will simulate random forest with 2 through 9 variables at each split. Using the MLeval package, we can quickly get the ROC value of .85 for this model.</p>
<pre><code>note: only 8 unique complexity parameters in default grid. Truncating the grid to 8 .</code></pre>
<p><img src="Figs/unnamed-chunk-7-1.png" width="1152" style="display: block; margin: auto;" /><img src="Figs/unnamed-chunk-7-2.png" width="1152" style="display: block; margin: auto;" /><img src="Figs/unnamed-chunk-7-3.png" width="1152" style="display: block; margin: auto;" /><img src="Figs/unnamed-chunk-7-4.png" width="1152" style="display: block; margin: auto;" /><img src="Figs/unnamed-chunk-7-5.png" width="1152" style="display: block; margin: auto;" /></p>
</div>
<div id="glmnet-model" class="section level2">
<h2><span class="header-section-number">6.2</span> Glmnet model</h2>
<p>Now we will look into the glmnet model with the same number of repeated folds. The tuning parameters for a glmnet uses lasso and ridge, denoted by alpha/lambda values. Here we will test around 40 values 2 from the alpha and 20 from lambda, as the different parameters of the glmnet. We end up with a ROC value of .79 so it seems like the random forest model is slightly better</p>
<pre class="r"><code>model &lt;- train(
  Classification ~ ., data = cancer,
  tuneGrid = expand.grid(alpha  = 0:1, 
                         lambda = seq(0.0001, 1, length = 20)),
  method = &quot;glmnet&quot;,
  trControl = myControl
)


max(model[[&quot;results&quot;]][[&quot;ROC&quot;]])</code></pre>
<pre><code>[1] 0.7965268</code></pre>
</div>
<div id="direct-comparison" class="section level2">
<h2><span class="header-section-number">6.3</span> Direct Comparison</h2>
<p>The previous examples of the models show how each model performed but we may not we sure where the folds were split, so we want to make sure they’re using the same splits. Here we put the models into <code>resamples()</code> to directly compare the model’s performances.</p>
<pre class="r"><code>set.seed(7)
myControl &lt;- trainControl(
  method = &quot;repeatedcv&quot;,
  number = 5,
  repeats = 5,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = FALSE
)


modelglmnet &lt;- train(x = cancer[, 1:9],
                     y = cancer[,10],
                     metric = &quot;ROC&quot;,
                     method = &quot;glmnet&quot;,
                     tuneGrid = expand.grid(alpha  = 0:1, 
                         lambda = seq(0.0001, 1, length = 20)),
                     trControl = myControl)


modelranger &lt;- train(Classification ~ ., 
               data = cancer,
               tuneLength = 9,
               metric = &quot;ROC&quot;,
               method = &quot;ranger&quot;,
               trControl = myControl)</code></pre>
<pre><code>note: only 8 unique complexity parameters in default grid. Truncating the grid to 8 .</code></pre>
<pre class="r"><code># Create model_list
model_list &lt;- list(glmnet = modelglmnet, rf = modelranger)
# Pass model_list to resamples(): ANS
ANS &lt;- resamples(model_list)
# Summarize the results
summary(ANS)</code></pre>
<pre><code>
Call:
summary.resamples(object = ANS)

Models: glmnet, rf 
Number of resamples: 25 

ROC 
            Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
glmnet 0.6384615 0.7202797 0.7622378 0.7746970 0.8333333 0.9230769    0
rf     0.6433566 0.7961538 0.8461538 0.8396014 0.8769231 0.9884615    0

Sens 
       Min.   1st Qu. Median      Mean   3rd Qu. Max. NA&#39;s
glmnet  0.4 0.5454545    0.7 0.6923636 0.8181818    1    0
rf      0.3 0.6000000    0.7 0.6967273 0.8000000    1    0

Spec 
            Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
glmnet 0.4615385 0.6666667 0.7692308 0.7248718 0.7692308    1    0
rf     0.5000000 0.7692308 0.8461538 0.8148718 0.8461538    1    0</code></pre>
<p>We can see that the random forest is better looking at the mean or median of their ROC values. Where rf mean = 0.8396014 and glmnet mean = 0.7746970 so a random forest model would be able to predict whether an individual is healthy or has breast cancer compare to a glmnet model.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
